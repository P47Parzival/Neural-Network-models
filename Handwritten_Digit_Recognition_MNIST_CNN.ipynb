{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cYk_iq0o8Hwp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ38BQRKIp9o",
        "outputId": "6c89979e-2ee2-4cf3-c8ee-67fd93e602b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "\n",
        "# hyperparameter\n",
        "batch_size = 64\n",
        "\n",
        "# transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5))\n",
        "    ])"
      ],
      "metadata": {
        "id": "h5b94CYwLkTa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "nq9qYfhoI9ek"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e5f1778f",
        "outputId": "c5f19f8c-4923-4429-d9c3-86c20b86282c"
      },
      "source": [
        "# Access a sample from the dataset\n",
        "image, label = train_dataset[0]\n",
        "\n",
        "# Display the image and label\n",
        "print(\"Label:\", label)\n",
        "display(image)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
              "          -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
              "           1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
              "           0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
              "           0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
              "          -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "           0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
              "          -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
              "          -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
              "          -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
              "           0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
              "           0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
              "           0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
              "           0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
              "           0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
              "           0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
              "          -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
              "           0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
              "           0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "1365260b",
        "outputId": "2299190b-3c6a-4ef2-c934-36dc3dda67a1"
      },
      "source": [
        "# image visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Access a sample from the dataset\n",
        "image, label = train_dataset[0]\n",
        "\n",
        "# The image tensor is normalized, so we need to denormalize it for display\n",
        "# The normalization was: transforms.Normalize((0.5), (0.5))\n",
        "# Denormalization: image * std + mean\n",
        "denormalized_image = image * 0.5 + 0.5\n",
        "\n",
        "# Convert the tensor to a NumPy array and remove the channel dimension for grayscale image\n",
        "image_np = denormalized_image.squeeze().numpy()\n",
        "\n",
        "# Display the image using Matplotlib\n",
        "plt.imshow(image_np, cmap='gray')\n",
        "plt.title(f'Label: {label}')\n",
        "plt.axis('off') # Hide axes\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAADppJREFUeJzt3H2s1/P/x/HnR6kURZTMyI6IXCyTwjK5Wky2Dm1GzRprhrb+EWFUttAolpKz8ZXWhiHXhlnlYrVyRjbXF9MfWirSlYss5/P74/v9PsevvpzXR+eiut22/ujs/Tjv92mru/dJr0q1Wq0GAETEPm39AAC0H6IAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKLAHmnVqlVRqVTivvvu22Wfc8mSJVGpVGLJkiW77HNCeyMKtBvz5s2LSqUSjY2Nbf0oLWLKlClRqVR2+NGlS5e2fjRIHdv6AWBvM3fu3Nh///3z5x06dGjDp4E/EwVoZaNGjYpDDjmkrR8Ddsq3j9it/Pbbb3HHHXfEqaeeGj169Ihu3brFWWedFYsXL/6fm/vvvz/69u0b++23X5x99tnx0Ucf7XDNZ599FqNGjYqePXtGly5dYtCgQfHiiy/+7fP8/PPP8dlnn8X333/f7K+hWq3G5s2bwwHFtEeiwG5l8+bN8cgjj8SwYcNi+vTpMWXKlFi/fn0MHz48Vq5cucP18+fPj1mzZsUNN9wQt9xyS3z00Udx7rnnxtq1a/Oajz/+OE4//fT49NNPY9KkSTFjxozo1q1bjBw5Mp577rm/fJ4VK1bE8ccfH7Nnz27211BXVxc9evSIAw44IMaMGfOnZ4G25ttH7FYOOuigWLVqVXTq1Ck/Nm7cuDjuuOPiwQcfjEcfffRP13/11Vfx5ZdfxuGHHx4RERdeeGEMGTIkpk+fHjNnzoyIiAkTJsSRRx4Z7733XnTu3DkiIq6//voYOnRo3HzzzVFfX7/Lnn38+PFxxhlnROfOneOdd96JOXPmxIoVK6KxsTG6d+++S+4D/4QosFvp0KFD/sVsU1NTbNy4MZqammLQoEHx/vvv73D9yJEjMwgREYMHD44hQ4bEq6++GjNnzowNGzbEokWL4s4774wtW7bEli1b8trhw4fH5MmTY/Xq1X/6HH80bNiwZn8baMKECX/6+WWXXRaDBw+O0aNHx0MPPRSTJk1q1ueBluTbR+x2Hn/88Tj55JOjS5cucfDBB0evXr3ilVdeiU2bNu1w7THHHLPDx4499thYtWpVRPz7TaJarcbtt98evXr1+tOPyZMnR0TEunXrWuxrufLKK6NPnz7x5ptvttg9oIQ3BXYrCxYsiLFjx8bIkSNj4sSJ0bt37+jQoUPcfffd8fXXXxd/vqampoiIuPHGG2P48OE7vaZfv37/6Jn/zhFHHBEbNmxo0XtAc4kCu5Vnnnkm6urqYuHChVGpVPLj//2v+v/vyy+/3OFjX3zxRRx11FER8e+/9I2I2HfffeP888/f9Q/8N6rVaqxatSpOOeWUVr837IxvH7Fb+e/fJ/zx+/jLly+PZcuW7fT6559/PlavXp0/X7FiRSxfvjwuuuiiiIjo3bt3DBs2LBoaGmLNmjU77NevX/+Xz1Pyv6Tu7HPNnTs31q9fHxdeeOHf7qE1eFOg3fnXv/4Vr7322g4fnzBhQowYMSIWLlwY9fX1cfHFF8c333wTDz/8cAwYMCC2bt26w6Zfv34xdOjQuO6662Lbtm3xwAMPxMEHHxw33XRTXjNnzpwYOnRonHTSSTFu3Lioq6uLtWvXxrJly+Lbb7+NDz/88H8+64oVK+Kcc86JyZMnx5QpU/7y6+rbt29cfvnlcdJJJ0WXLl3i3XffjSeffDIGDhwY1157bfN/gaAFiQLtzty5c3f68bFjx8bYsWPju+++i4aGhnj99ddjwIABsWDBgnj66ad3elDdVVddFfvss0888MADsW7duhg8eHDMnj07DjvssLxmwIAB0djYGFOnTo158+bFDz/8EL17945TTjkl7rjjjl32dY0ePTqWLl0azz77bPz666/Rt2/fuOmmm+K2226Lrl277rL7wD9RqfpnlQD8h79TACCJAgBJFABIogBAEgUAkigAkJr97xT+eKQAALuf5vwLBG8KACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKSObf0A8Hc6dOhQvOnRo0cLPMmuMX78+Jp2Xbt2Ld7079+/eHPDDTcUb+67777izRVXXFG8iYj49ddfizf33HNP8Wbq1KnFmz2BNwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQH4u1hjjzyyOJNp06dijdnnnlm8Wbo0KHFm4iIAw88sHhz2WWX1XSvPc23335bvJk1a1bxpr6+vnizZcuW4k1ExIcffli8eeutt2q6197ImwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKlWq1Wm3VhpdLSz8IfDBw4sKbdokWLijc9evSo6V60rqampuLN1VdfXbzZunVr8aYWa9asqWn3448/Fm8+//zzmu61p2nOH/feFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgOSU1HaqZ8+eNe2WL19evKmrq6vpXnuaWn7tNm7cWLw555xzijcREb/99lvxxgm4/JFTUgEoIgoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAKljWz8AO7dhw4aadhMnTizejBgxonjzwQcfFG9mzZpVvKnVypUrizcXXHBB8eann34q3pxwwgnFm4iICRMm1LSDEt4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQKtVqtdqsCyuVln4W2kj37t2LN1u2bCneNDQ0FG8iIq655prizZgxY4o3TzzxRPEGdifN+ePemwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFLHtn4A2t7mzZtb5T6bNm1qlftERIwbN65489RTTxVvmpqaijfQnnlTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUqVarVabdWGl0tLPwh6uW7duNe1eeuml4s3ZZ59dvLnooouKN2+88UbxBtpKc/6496YAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkQDzavaOPPrp48/777xdvNm7cWLxZvHhx8aaxsbF4ExExZ86c4k0zf3uzl3AgHgBFRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIDkQjz1SfX198eaxxx4r3hxwwAHFm1rdeuutxZv58+cXb9asWVO8YffgQDwAiogCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByIB78x4knnli8mTlzZvHmvPPOK97UqqGhoXgzbdq04s3q1auLN7Q+B+IBUEQUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSA/HgHzjwwAOLN5dccklN93rssceKN7X8vl20aFHx5oILLije0PociAdAEVEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEBySirsJrZt21a86dixY/Fm+/btxZvhw4cXb5YsWVK84Z9xSioARUQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCVn5YFe6iTTz65eDNq1KjizWmnnVa8iajtcLtafPLJJ8Wbt99+uwWehLbgTQGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAMmBeLR7/fv3L96MHz++eHPppZcWb/r06VO8aU2///578WbNmjXFm6ampuIN7ZM3BQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJAfiUZNaDoK74oorarpXLYfbHXXUUTXdqz1rbGws3kybNq148+KLLxZv2HN4UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHIg3h7m0EMPLd4MGDCgeDN79uzizXHHHVe8ae+WL19evLn33ntrutcLL7xQvGlqaqrpXuy9vCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJKamtoGfPnsWbhoaGmu41cODA4k1dXV1N92rPli5dWryZMWNG8eb1118v3vzyyy/FG2gt3hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJD26gPxhgwZUryZOHFi8Wbw4MHFm8MPP7x40979/PPPNe1mzZpVvLnrrruKNz/99FPxBvY03hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJD26gPx6uvrW2XTmj755JPizcsvv1y82b59e/FmxowZxZuIiI0bN9a0A8p5UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQKpUq9Vqsy6sVFr6WQBoQc35496bAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKSOzb2wWq225HMA0A54UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAg/R+J6Mjw+/r7+gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataLoaders\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "kjATvlV1OReC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the CNN code\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(32*7*7, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "    x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "    # flatten the image\n",
        "    x = x.view(-1, 32*7*7)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "# moving model to GPU\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "7DrfILDyPf_R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# workflow visualization\n",
        "from torchviz import make_dot\n",
        "import torch\n",
        "\n",
        "model = CNN()\n",
        "x = torch.randn(1, 1, 28, 28)  # Dummy input\n",
        "y = model(x)\n",
        "dot = make_dot(y, params=dict(model.named_parameters()))\n",
        "dot.render(\"cnn_model\", format=\"png\")  # Saves as PNG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j_AALOeSPhTP",
        "outputId": "8e1f5cb2-c031-45b8-f05b-572db597369b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cnn_model.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "4M7mSWW-U1Ja"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model, trianing loop\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # moving to gpu\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print (f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afz6v2WEV187",
        "outputId": "6edcf7e8-2678-45ea-8adf-3f359bcddee2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/938], Loss: 0.3038\n",
            "Epoch [1/5], Step [200/938], Loss: 0.2056\n",
            "Epoch [1/5], Step [300/938], Loss: 0.1405\n",
            "Epoch [1/5], Step [400/938], Loss: 0.0845\n",
            "Epoch [1/5], Step [500/938], Loss: 0.0651\n",
            "Epoch [1/5], Step [600/938], Loss: 0.1211\n",
            "Epoch [1/5], Step [700/938], Loss: 0.0350\n",
            "Epoch [1/5], Step [800/938], Loss: 0.0834\n",
            "Epoch [1/5], Step [900/938], Loss: 0.0572\n",
            "Epoch [2/5], Step [100/938], Loss: 0.0244\n",
            "Epoch [2/5], Step [200/938], Loss: 0.2844\n",
            "Epoch [2/5], Step [300/938], Loss: 0.0068\n",
            "Epoch [2/5], Step [400/938], Loss: 0.0888\n",
            "Epoch [2/5], Step [500/938], Loss: 0.0641\n",
            "Epoch [2/5], Step [600/938], Loss: 0.0959\n",
            "Epoch [2/5], Step [700/938], Loss: 0.0175\n",
            "Epoch [2/5], Step [800/938], Loss: 0.0031\n",
            "Epoch [2/5], Step [900/938], Loss: 0.0546\n",
            "Epoch [3/5], Step [100/938], Loss: 0.0283\n",
            "Epoch [3/5], Step [200/938], Loss: 0.0083\n",
            "Epoch [3/5], Step [300/938], Loss: 0.0413\n",
            "Epoch [3/5], Step [400/938], Loss: 0.0226\n",
            "Epoch [3/5], Step [500/938], Loss: 0.0046\n",
            "Epoch [3/5], Step [600/938], Loss: 0.0177\n",
            "Epoch [3/5], Step [700/938], Loss: 0.0115\n",
            "Epoch [3/5], Step [800/938], Loss: 0.0052\n",
            "Epoch [3/5], Step [900/938], Loss: 0.0082\n",
            "Epoch [4/5], Step [100/938], Loss: 0.0378\n",
            "Epoch [4/5], Step [200/938], Loss: 0.0186\n",
            "Epoch [4/5], Step [300/938], Loss: 0.0037\n",
            "Epoch [4/5], Step [400/938], Loss: 0.0117\n",
            "Epoch [4/5], Step [500/938], Loss: 0.0201\n",
            "Epoch [4/5], Step [600/938], Loss: 0.0410\n",
            "Epoch [4/5], Step [700/938], Loss: 0.0276\n",
            "Epoch [4/5], Step [800/938], Loss: 0.0550\n",
            "Epoch [4/5], Step [900/938], Loss: 0.0134\n",
            "Epoch [5/5], Step [100/938], Loss: 0.0098\n",
            "Epoch [5/5], Step [200/938], Loss: 0.0071\n",
            "Epoch [5/5], Step [300/938], Loss: 0.1328\n",
            "Epoch [5/5], Step [400/938], Loss: 0.0038\n",
            "Epoch [5/5], Step [500/938], Loss: 0.0302\n",
            "Epoch [5/5], Step [600/938], Loss: 0.0109\n",
            "Epoch [5/5], Step [700/938], Loss: 0.1179\n",
            "Epoch [5/5], Step [800/938], Loss: 0.0014\n",
            "Epoch [5/5], Step [900/938], Loss: 0.0316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWs65c3BW3Ky",
        "outputId": "a5ac512b-3151-4e78-f7cc-10bdbd29db34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader: # Corrected 'loders' to 'labels'\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device) # Move labels to the same device as images and model\n",
        "    output = model(images)\n",
        "\n",
        "    _, predicted = torch.max(output.data,1)\n",
        "    n_samples = n_samples + labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network on the 10000 test images: {acc:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxpqKcYfXdjf",
        "outputId": "f4acff6d-c8f7-46e1-d95a-404710c4ea43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 99.07 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FfmboGO6YF3r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}